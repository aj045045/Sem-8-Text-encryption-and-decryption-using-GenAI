{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":3952946,"sourceType":"datasetVersion","datasetId":1554380}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install ninja scipy click tqdm pyspng imageio-ffmpeg\n!pip install torch torchvision --extra-index-url https://download.pytorch.org/whl/cu118","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T12:36:13.149203Z","iopub.execute_input":"2025-06-09T12:36:13.149751Z","iopub.status.idle":"2025-06-09T12:36:29.304757Z","shell.execute_reply.started":"2025-06-09T12:36:13.149727Z","shell.execute_reply":"2025-06-09T12:36:29.303880Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: ninja in /usr/local/lib/python3.11/dist-packages (1.11.1.4)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.15.2)\nRequirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (8.1.8)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\nCollecting pyspng\n  Downloading pyspng-0.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.0 kB)\nRequirement already satisfied: imageio-ffmpeg in /usr/local/lib/python3.11/dist-packages (0.6.0)\nRequirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.5,>=1.23.5->scipy) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.5,>=1.23.5->scipy) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.5,>=1.23.5->scipy) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.5,>=1.23.5->scipy) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.5,>=1.23.5->scipy) (2024.2.0)\nDownloading pyspng-0.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (196 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.1/196.1 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: pyspng\nSuccessfully installed pyspng-0.1.3\nLooking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu118\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision) (2024.2.0)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m158.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m^C:01\u001b[0m\n\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m158.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!git clone https://github.com/NVlabs/stylegan3.git\n%cd stylegan3","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T12:36:32.409657Z","iopub.execute_input":"2025-06-09T12:36:32.410213Z","iopub.status.idle":"2025-06-09T12:36:33.230839Z","shell.execute_reply.started":"2025-06-09T12:36:32.410184Z","shell.execute_reply":"2025-06-09T12:36:33.230028Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'stylegan3'...\nremote: Enumerating objects: 212, done.\u001b[K\nremote: Counting objects: 100% (163/163), done.\u001b[K\nremote: Compressing objects: 100% (73/73), done.\u001b[K\nremote: Total 212 (delta 99), reused 90 (delta 90), pack-reused 49 (from 1)\u001b[K\nReceiving objects: 100% (212/212), 4.16 MiB | 14.16 MiB/s, done.\nResolving deltas: 100% (108/108), done.\n/kaggle/working/stylegan3/stylegan3/stylegan3/stylegan3/stylegan3\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import os\nimport shutil\nfrom PIL import Image\n\nsource_dir = \"/kaggle/input/animal-image-dataset-90-different-animals\"\ntarget_dir = \"/kaggle/working/animal_dataset\"\n\nos.makedirs(target_dir, exist_ok=True)\n\n# Flatten and resize images\nfor root, _, files in os.walk(source_dir):\n    for file in files:\n        if file.endswith(('jpg', 'png', 'jpeg')):\n            img_path = os.path.join(root, file)\n            img = Image.open(img_path).convert('RGB')\n            img = img.resize((512, 512))  # Resize to 512x512\n            img.save(os.path.join(target_dir, file))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T12:36:37.230039Z","iopub.execute_input":"2025-06-09T12:36:37.230817Z","iopub.status.idle":"2025-06-09T12:39:00.522146Z","shell.execute_reply.started":"2025-06-09T12:36:37.230772Z","shell.execute_reply":"2025-06-09T12:39:00.521351Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# For StyleGAN2-ADA / StyleGAN3 (latest version):\n!python /kaggle/working/stylegan3/dataset_tool.py --source=/kaggle/working/animal_dataset --dest=/kaggle/working/animal_dataset.zip --resolution=1024x1024","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T12:39:06.036859Z","iopub.execute_input":"2025-06-09T12:39:06.037566Z","iopub.status.idle":"2025-06-09T12:46:40.526011Z","shell.execute_reply.started":"2025-06-09T12:39:06.037537Z","shell.execute_reply":"2025-06-09T12:46:40.525334Z"}},"outputs":[{"name":"stdout","text":"100%|███████████████████████████████████████| 5399/5399 [07:33<00:00, 11.90it/s]\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import torch\ntorch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T12:47:10.188257Z","iopub.execute_input":"2025-06-09T12:47:10.188906Z","iopub.status.idle":"2025-06-09T12:47:13.986374Z","shell.execute_reply.started":"2025-06-09T12:47:10.188877Z","shell.execute_reply":"2025-06-09T12:47:13.985858Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# !wget https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/stylegan3-t-ffhqu-256x256.pkl -O stylegan3-pretrained.pkl\n!wget https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/stylegan3-t-ffhq-1024x1024.pkl -O stylegan3-pretrained.pkl\n!ls -lh /kaggle/working/stylegan3-pretrained.pkl\n!mv stylegan3-pretrained.pkl /kaggle/working/\n!ls -lh /kaggle/working/stylegan3-pretrained.pkl","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T12:47:15.774934Z","iopub.execute_input":"2025-06-09T12:47:15.775566Z","iopub.status.idle":"2025-06-09T12:47:19.557489Z","shell.execute_reply.started":"2025-06-09T12:47:15.775544Z","shell.execute_reply":"2025-06-09T12:47:19.556825Z"}},"outputs":[{"name":"stdout","text":"--2025-06-09 12:47:15--  https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/stylegan3-t-ffhq-1024x1024.pkl\nResolving api.ngc.nvidia.com (api.ngc.nvidia.com)... 52.25.204.74, 54.68.249.82\nConnecting to api.ngc.nvidia.com (api.ngc.nvidia.com)|52.25.204.74|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://xfiles.ngc.nvidia.com/org/nvidia/team/research/models/stylegan3/versions/1/files/stylegan3-t-ffhq-1024x1024.pkl?ssec-algo=AES256&versionId=Pq0TsLpbrJL8kNRN4xGQsr_DcEvFQ4xJ&ssec-key=AChvfpU%2BKC9EBiFIu4vP8aYWmDqgfSncQhrQQMjDKIsLo%2B5X32wRb8sFfyi69%2BdYwowChMQgmUy9q6vS8WMQ0fq%2FGnr2z8NfCufLK2XS5asZrxPcz%2BdNe14hDAHCjKmd5v5gVxyOVKEhGN4TjbCKv8kqtZyvEbtqdqU2ny94gva1iXG2CWa0QIhk%2B9zopmiz6h4L3I9ID5vJkZmKuY7zHorGj5YT7kye2FVDNHPpNhhtxs168bermc6U6rhRJuDUzKVhRFJkvLaq4SqbF3r9CXPxFtSC4SxoLWiyyZoqeXYbN61P6nJG359zZD6P6xt0wNXuutolhxOyh0vjZXLEQMpCImzFo7rCtN3UNRqs9Ms%2Bt66Bjym882YG%2BrZIQcaNACyr9Vi2cAGd7NWLyVy3FsUN28enxX6Q2YDjhLTjZZSStuoisrl1B32lENYZL%2BGWOxlkmVgAdAt%2BAx1EyTarKJvkco4P5QsBYV66o7tHulZ2Lu2azYWqToJWCofDJFf%2B&Signature=CVzky6OfpEwpfCA-hGZbTAPaLJF0mTfOMdE39yOoXD1mTKLN~WV3HmqFz9rsLk~g4ytX07lP-XrTH4ZBeMcfKEPMNGVX0wgi30obh0N81mNf7ETrPeJc3rvcz90F946I4bL1uoFqnBge8aXMYxdNpVbKJGY6LLJXA~NNtDFadiGSRolkvdsy4RLQIiMdvAkw9Vv7WoCB7RdFC~HH02oM-g606f7yab5VXSRXN9wdU6eVC0AkCMTx8aUwfy0ZDGUPSdrA4DZaSJxBdGdiuBbzNWfXEvIKjmR0lqGT-2lwH5xoajRnL9WWMacmDJikNNBPhbBb7neFKqo6dJmdQCdTYw__&kid=bXJrLWU3OGM1M2FhZjE4YzRiNmJiNjlkYmRhZjcxNjA3YWEw&Expires=1749559635&Key-Pair-Id=KCX06E8E9L60W&ssec-enabled=true [following]\n--2025-06-09 12:47:15--  https://xfiles.ngc.nvidia.com/org/nvidia/team/research/models/stylegan3/versions/1/files/stylegan3-t-ffhq-1024x1024.pkl?ssec-algo=AES256&versionId=Pq0TsLpbrJL8kNRN4xGQsr_DcEvFQ4xJ&ssec-key=AChvfpU%2BKC9EBiFIu4vP8aYWmDqgfSncQhrQQMjDKIsLo%2B5X32wRb8sFfyi69%2BdYwowChMQgmUy9q6vS8WMQ0fq%2FGnr2z8NfCufLK2XS5asZrxPcz%2BdNe14hDAHCjKmd5v5gVxyOVKEhGN4TjbCKv8kqtZyvEbtqdqU2ny94gva1iXG2CWa0QIhk%2B9zopmiz6h4L3I9ID5vJkZmKuY7zHorGj5YT7kye2FVDNHPpNhhtxs168bermc6U6rhRJuDUzKVhRFJkvLaq4SqbF3r9CXPxFtSC4SxoLWiyyZoqeXYbN61P6nJG359zZD6P6xt0wNXuutolhxOyh0vjZXLEQMpCImzFo7rCtN3UNRqs9Ms%2Bt66Bjym882YG%2BrZIQcaNACyr9Vi2cAGd7NWLyVy3FsUN28enxX6Q2YDjhLTjZZSStuoisrl1B32lENYZL%2BGWOxlkmVgAdAt%2BAx1EyTarKJvkco4P5QsBYV66o7tHulZ2Lu2azYWqToJWCofDJFf%2B&Signature=CVzky6OfpEwpfCA-hGZbTAPaLJF0mTfOMdE39yOoXD1mTKLN~WV3HmqFz9rsLk~g4ytX07lP-XrTH4ZBeMcfKEPMNGVX0wgi30obh0N81mNf7ETrPeJc3rvcz90F946I4bL1uoFqnBge8aXMYxdNpVbKJGY6LLJXA~NNtDFadiGSRolkvdsy4RLQIiMdvAkw9Vv7WoCB7RdFC~HH02oM-g606f7yab5VXSRXN9wdU6eVC0AkCMTx8aUwfy0ZDGUPSdrA4DZaSJxBdGdiuBbzNWfXEvIKjmR0lqGT-2lwH5xoajRnL9WWMacmDJikNNBPhbBb7neFKqo6dJmdQCdTYw__&kid=bXJrLWU3OGM1M2FhZjE4YzRiNmJiNjlkYmRhZjcxNjA3YWEw&Expires=1749559635&Key-Pair-Id=KCX06E8E9L60W&ssec-enabled=true\nResolving xfiles.ngc.nvidia.com (xfiles.ngc.nvidia.com)... 18.238.217.125, 18.238.217.99, 18.238.217.100, ...\nConnecting to xfiles.ngc.nvidia.com (xfiles.ngc.nvidia.com)|18.238.217.125|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 294775112 (281M) [application/x-zerosize]\nSaving to: ‘stylegan3-pretrained.pkl’\n\nstylegan3-pretraine 100%[===================>] 281.12M  99.2MB/s    in 2.8s    \n\n2025-06-09 12:47:19 (99.2 MB/s) - ‘stylegan3-pretrained.pkl’ saved [294775112/294775112]\n\nls: cannot access '/kaggle/working/stylegan3-pretrained.pkl': No such file or directory\n-rw-r--r-- 1 root root 282M Mar  1 03:35 /kaggle/working/stylegan3-pretrained.pkl\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Replace this logic in your launch_training or run script\nfrom training import training_loop\nimport legacy\n\nwith open('/kaggle/working/stylegan3-pretrained.pkl', 'rb') as f:\n    resume_data = legacy.load_network_pkl(f)\n    G = resume_data['G']\n    print(G.z_dim, G.w_dim, G.mapping.num_layers)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T12:47:21.078884Z","iopub.execute_input":"2025-06-09T12:47:21.079564Z","iopub.status.idle":"2025-06-09T12:47:23.341424Z","shell.execute_reply.started":"2025-06-09T12:47:21.079530Z","shell.execute_reply":"2025-06-09T12:47:23.340661Z"}},"outputs":[{"name":"stdout","text":"512 512 2\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"!python /kaggle/working/stylegan3/train.py \\\n  --outdir=/kaggle/working/animal-stylegan-results \\\n  --cfg=stylegan3-t \\\n  --data=/kaggle/working/animal_dataset.zip \\\n  --gpus=1 \\\n  --batch=8 \\\n  --mirror=1 \\\n  --resume=/kaggle/working/stylegan3-pretrained.pkl \\\n  --gamma=8 \\\n  --snap=10 \\\n  --kimg=500","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T13:16:55.586716Z","iopub.execute_input":"2025-06-09T13:16:55.587213Z","iopub.status.idle":"2025-06-09T13:31:03.745445Z","shell.execute_reply.started":"2025-06-09T13:16:55.587173Z","shell.execute_reply":"2025-06-09T13:31:03.744473Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"\nTraining options:\n{\n  \"G_kwargs\": {\n    \"class_name\": \"training.networks_stylegan3.Generator\",\n    \"z_dim\": 512,\n    \"w_dim\": 512,\n    \"mapping_kwargs\": {\n      \"num_layers\": 2\n    },\n    \"channel_base\": 32768,\n    \"channel_max\": 512,\n    \"magnitude_ema_beta\": 0.9997227795604651\n  },\n  \"D_kwargs\": {\n    \"class_name\": \"training.networks_stylegan2.Discriminator\",\n    \"block_kwargs\": {\n      \"freeze_layers\": 0\n    },\n    \"mapping_kwargs\": {},\n    \"epilogue_kwargs\": {\n      \"mbstd_group_size\": 4\n    },\n    \"channel_base\": 32768,\n    \"channel_max\": 512\n  },\n  \"G_opt_kwargs\": {\n    \"class_name\": \"torch.optim.Adam\",\n    \"betas\": [\n      0.0,\n      0.99\n    ],\n    \"eps\": 1e-08,\n    \"lr\": 0.0025\n  },\n  \"D_opt_kwargs\": {\n    \"class_name\": \"torch.optim.Adam\",\n    \"betas\": [\n      0.0,\n      0.99\n    ],\n    \"eps\": 1e-08,\n    \"lr\": 0.002\n  },\n  \"loss_kwargs\": {\n    \"class_name\": \"training.loss.StyleGAN2Loss\",\n    \"r1_gamma\": 8.0,\n    \"blur_init_sigma\": 0\n  },\n  \"data_loader_kwargs\": {\n    \"pin_memory\": true,\n    \"prefetch_factor\": 2,\n    \"num_workers\": 3\n  },\n  \"training_set_kwargs\": {\n    \"class_name\": \"training.dataset.ImageFolderDataset\",\n    \"path\": \"/kaggle/working/animal_dataset.zip\",\n    \"use_labels\": false,\n    \"max_size\": 5399,\n    \"xflip\": true,\n    \"resolution\": 1024,\n    \"random_seed\": 0\n  },\n  \"num_gpus\": 1,\n  \"batch_size\": 8,\n  \"batch_gpu\": 8,\n  \"metrics\": [\n    \"fid50k_full\"\n  ],\n  \"total_kimg\": 1000,\n  \"kimg_per_tick\": 4,\n  \"image_snapshot_ticks\": 10,\n  \"network_snapshot_ticks\": 10,\n  \"random_seed\": 0,\n  \"ema_kimg\": 2.5,\n  \"augment_kwargs\": {\n    \"class_name\": \"training.augment.AugmentPipe\",\n    \"xflip\": 1,\n    \"rotate90\": 1,\n    \"xint\": 1,\n    \"scale\": 1,\n    \"rotate\": 1,\n    \"aniso\": 1,\n    \"xfrac\": 1,\n    \"brightness\": 1,\n    \"contrast\": 1,\n    \"lumaflip\": 1,\n    \"hue\": 1,\n    \"saturation\": 1\n  },\n  \"ada_target\": 0.6,\n  \"resume_pkl\": \"/kaggle/working/stylegan3-pretrained.pkl\",\n  \"ada_kimg\": 100,\n  \"ema_rampup\": null,\n  \"run_dir\": \"/kaggle/working/animal-stylegan-results/00002-stylegan3-t-animal_dataset-gpus1-batch8-gamma8\"\n}\n\nOutput directory:    /kaggle/working/animal-stylegan-results/00002-stylegan3-t-animal_dataset-gpus1-batch8-gamma8\nNumber of GPUs:      1\nBatch size:          8 images\nTraining duration:   1000 kimg\nDataset path:        /kaggle/working/animal_dataset.zip\nDataset size:        5399 images\nDataset resolution:  1024\nDataset labels:      False\nDataset x-flips:     True\n\nCreating output directory...\nLaunching processes...\nLoading training set...\n/usr/local/lib/python3.11/dist-packages/torch/utils/data/sampler.py:77: UserWarning: `data_source` argument is not used and will be removed in 2.2.0.You may still have custom implementation that utilizes it.\n  warnings.warn(\n\nNum images:  10798\nImage shape: [3, 1024, 1024]\nLabel shape: [0]\n\nConstructing networks...\nResuming from \"/kaggle/working/stylegan3-pretrained.pkl\"\nSetting up PyTorch plugin \"bias_act_plugin\"... /usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:2059: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \nIf this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n  warnings.warn(\nDone.\nSetting up PyTorch plugin \"filtered_lrelu_plugin\"... /usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:2059: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \nIf this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n  warnings.warn(\nDone.\n\nGenerator                     Parameters  Buffers  Output shape         Datatype\n---                           ---         ---      ---                  ---     \nmapping.fc0                   262656      -        [8, 512]             float32 \nmapping.fc1                   262656      -        [8, 512]             float32 \nmapping                       -           512      [8, 16, 512]         float32 \nsynthesis.input.affine        2052        -        [8, 4]               float32 \nsynthesis.input               262144      1545     [8, 512, 36, 36]     float32 \nsynthesis.L0_36_512.affine    262656      -        [8, 512]             float32 \nsynthesis.L0_36_512           2359808     25       [8, 512, 36, 36]     float32 \nsynthesis.L1_36_512.affine    262656      -        [8, 512]             float32 \nsynthesis.L1_36_512           2359808     25       [8, 512, 36, 36]     float32 \nsynthesis.L2_52_512.affine    262656      -        [8, 512]             float32 \nsynthesis.L2_52_512           2359808     37       [8, 512, 52, 52]     float32 \nsynthesis.L3_52_512.affine    262656      -        [8, 512]             float32 \nsynthesis.L3_52_512           2359808     25       [8, 512, 52, 52]     float32 \nsynthesis.L4_84_512.affine    262656      -        [8, 512]             float32 \nsynthesis.L4_84_512           2359808     37       [8, 512, 84, 84]     float32 \nsynthesis.L5_148_512.affine   262656      -        [8, 512]             float32 \nsynthesis.L5_148_512          2359808     37       [8, 512, 148, 148]   float16 \nsynthesis.L6_148_512.affine   262656      -        [8, 512]             float32 \nsynthesis.L6_148_512          2359808     25       [8, 512, 148, 148]   float16 \nsynthesis.L7_276_323.affine   262656      -        [8, 512]             float32 \nsynthesis.L7_276_323          1488707     37       [8, 323, 276, 276]   float16 \nsynthesis.L8_276_203.affine   165699      -        [8, 323]             float32 \nsynthesis.L8_276_203          590324      25       [8, 203, 276, 276]   float16 \nsynthesis.L9_532_128.affine   104139      -        [8, 203]             float32 \nsynthesis.L9_532_128          233984      37       [8, 128, 532, 532]   float16 \nsynthesis.L10_1044_81.affine  65664       -        [8, 128]             float32 \nsynthesis.L10_1044_81         93393       37       [8, 81, 1044, 1044]  float16 \nsynthesis.L11_1044_51.affine  41553       -        [8, 81]              float32 \nsynthesis.L11_1044_51         37230       25       [8, 51, 1044, 1044]  float16 \nsynthesis.L12_1044_32.affine  26163       -        [8, 51]              float32 \nsynthesis.L12_1044_32         14720       25       [8, 32, 1044, 1044]  float16 \nsynthesis.L13_1024_32.affine  16416       -        [8, 32]              float32 \nsynthesis.L13_1024_32         9248        25       [8, 32, 1024, 1024]  float16 \nsynthesis.L14_1024_3.affine   16416       -        [8, 32]              float32 \nsynthesis.L14_1024_3          99          1        [8, 3, 1024, 1024]   float16 \nsynthesis                     -           -        [8, 3, 1024, 1024]   float32 \n---                           ---         ---      ---                  ---     \nTotal                         22313167    2480     -                    -       \n\nSetting up PyTorch plugin \"upfirdn2d_plugin\"... /usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:2059: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \nIf this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n  warnings.warn(\nDone.\n\nDiscriminator  Parameters  Buffers  Output shape         Datatype\n---            ---         ---      ---                  ---     \nb1024.fromrgb  128         16       [8, 32, 1024, 1024]  float16 \nb1024.skip     2048        16       [8, 64, 512, 512]    float16 \nb1024.conv0    9248        16       [8, 32, 1024, 1024]  float16 \nb1024.conv1    18496       16       [8, 64, 512, 512]    float16 \nb1024          -           16       [8, 64, 512, 512]    float16 \nb512.skip      8192        16       [8, 128, 256, 256]   float16 \nb512.conv0     36928       16       [8, 64, 512, 512]    float16 \nb512.conv1     73856       16       [8, 128, 256, 256]   float16 \nb512           -           16       [8, 128, 256, 256]   float16 \nb256.skip      32768       16       [8, 256, 128, 128]   float16 \nb256.conv0     147584      16       [8, 128, 256, 256]   float16 \nb256.conv1     295168      16       [8, 256, 128, 128]   float16 \nb256           -           16       [8, 256, 128, 128]   float16 \nb128.skip      131072      16       [8, 512, 64, 64]     float16 \nb128.conv0     590080      16       [8, 256, 128, 128]   float16 \nb128.conv1     1180160     16       [8, 512, 64, 64]     float16 \nb128           -           16       [8, 512, 64, 64]     float16 \nb64.skip       262144      16       [8, 512, 32, 32]     float32 \nb64.conv0      2359808     16       [8, 512, 64, 64]     float32 \nb64.conv1      2359808     16       [8, 512, 32, 32]     float32 \nb64            -           16       [8, 512, 32, 32]     float32 \nb32.skip       262144      16       [8, 512, 16, 16]     float32 \nb32.conv0      2359808     16       [8, 512, 32, 32]     float32 \nb32.conv1      2359808     16       [8, 512, 16, 16]     float32 \nb32            -           16       [8, 512, 16, 16]     float32 \nb16.skip       262144      16       [8, 512, 8, 8]       float32 \nb16.conv0      2359808     16       [8, 512, 16, 16]     float32 \nb16.conv1      2359808     16       [8, 512, 8, 8]       float32 \nb16            -           16       [8, 512, 8, 8]       float32 \nb8.skip        262144      16       [8, 512, 4, 4]       float32 \nb8.conv0       2359808     16       [8, 512, 8, 8]       float32 \nb8.conv1       2359808     16       [8, 512, 4, 4]       float32 \nb8             -           16       [8, 512, 4, 4]       float32 \nb4.mbstd       -           -        [8, 513, 4, 4]       float32 \nb4.conv        2364416     16       [8, 512, 4, 4]       float32 \nb4.fc          4194816     -        [8, 512]             float32 \nb4.out         513         -        [8, 1]               float32 \n---            ---         ---      ---                  ---     \nTotal          29012513    544      -                    -       \n\nSetting up augmentation...\nDistributing across 1 GPUs...\nSetting up training phases...\nExporting sample images...\nInitializing logs...\n2025-06-09 13:18:49.793287: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1749475129.816753     413 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1749475129.823964     413 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nTraining for 1000 kimg...\n\ntick 0     kimg 0.0      time 5m 34s       sec/tick 219.2   sec/kimg 27397.69 maintenance 115.3  cpumem 3.28   gpumem 13.81  reserved 14.52  augment 0.000\nEvaluating metrics...\n^C\n\nAborted!\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"!tail -n 20 /kaggle/working/animal-stylegan-results/00002-stylegan3-t-animal_dataset-gpus1-batch16-gamma8/log.txt","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!python /kaggle/working/stylegan3/gen_images.py \\\n  --outdir=/kaggle/working/generated-animals \\\n  --trunc=1 \\\n  --seeds=1-10 \\\n  --network=/kaggle/working/animal-stylegan-results/00002-stylegan3-t-animal_dataset-gpus1-batch8-gamma8/network-snapshot-000000.pkl","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T13:32:15.931856Z","iopub.execute_input":"2025-06-09T13:32:15.932479Z","iopub.status.idle":"2025-06-09T13:32:26.995534Z","shell.execute_reply.started":"2025-06-09T13:32:15.932449Z","shell.execute_reply":"2025-06-09T13:32:26.994812Z"}},"outputs":[{"name":"stdout","text":"Loading networks from \"/kaggle/working/animal-stylegan-results/00002-stylegan3-t-animal_dataset-gpus1-batch8-gamma8/network-snapshot-000000.pkl\"...\nGenerating image for seed 1 (0/10) ...\nSetting up PyTorch plugin \"bias_act_plugin\"... /usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:2059: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \nIf this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n  warnings.warn(\nDone.\nSetting up PyTorch plugin \"filtered_lrelu_plugin\"... /usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:2059: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \nIf this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n  warnings.warn(\nDone.\nGenerating image for seed 2 (1/10) ...\nGenerating image for seed 3 (2/10) ...\nGenerating image for seed 4 (3/10) ...\nGenerating image for seed 5 (4/10) ...\nGenerating image for seed 6 (5/10) ...\nGenerating image for seed 7 (6/10) ...\nGenerating image for seed 8 (7/10) ...\nGenerating image for seed 9 (8/10) ...\nGenerating image for seed 10 (9/10) ...\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"%rm -rf /kaggle/working/*","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T12:33:13.372571Z","iopub.execute_input":"2025-06-09T12:33:13.372849Z","iopub.status.idle":"2025-06-09T12:33:13.911785Z","shell.execute_reply.started":"2025-06-09T12:33:13.372829Z","shell.execute_reply":"2025-06-09T12:33:13.910971Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"%%writefile /kaggle/working/stylegan3/train.py\n# %load /kaggle/working/stylegan3/train.py\n# Copyright (c) 2021, NVIDIA CORPORATION & AFFILIATES.  All rights reserved.\n#\n# NVIDIA CORPORATION and its licensors retain all intellectual property\n# and proprietary rights in and to this software, related documentation\n# and any modifications thereto.  Any use, reproduction, disclosure or\n# distribution of this software and related documentation without an express\n# license agreement from NVIDIA CORPORATION is strictly prohibited.\n\n\"\"\"Train a GAN using the techniques described in the paper\n\"Alias-Free Generative Adversarial Networks\".\"\"\"\n\nimport os\nimport click\nimport re\nimport json\nimport tempfile\nimport torch\n\nimport dnnlib\nfrom training import training_loop\nfrom metrics import metric_main\nfrom torch_utils import training_stats\nfrom torch_utils import custom_ops\n\n#----------------------------------------------------------------------------\n\ndef subprocess_fn(rank, c, temp_dir):\n    dnnlib.util.Logger(file_name=os.path.join(c.run_dir, 'log.txt'), file_mode='a', should_flush=True)\n\n    # Init torch.distributed.\n    if c.num_gpus > 1:\n        init_file = os.path.abspath(os.path.join(temp_dir, '.torch_distributed_init'))\n        if os.name == 'nt':\n            init_method = 'file:///' + init_file.replace('\\\\', '/')\n            torch.distributed.init_process_group(backend='gloo', init_method=init_method, rank=rank, world_size=c.num_gpus)\n        else:\n            init_method = f'file://{init_file}'\n            torch.distributed.init_process_group(backend='nccl', init_method=init_method, rank=rank, world_size=c.num_gpus)\n\n    # Init torch_utils.\n    sync_device = torch.device('cuda', rank) if c.num_gpus > 1 else None\n    training_stats.init_multiprocessing(rank=rank, sync_device=sync_device)\n    if rank != 0:\n        custom_ops.verbosity = 'none'\n\n    # Execute training loop.\n    training_loop.training_loop(rank=rank, **c)\n\n#----------------------------------------------------------------------------\n\ndef launch_training(c, desc, outdir, dry_run):\n    dnnlib.util.Logger(should_flush=True)\n\n    # Pick output directory.\n    prev_run_dirs = []\n    if os.path.isdir(outdir):\n        prev_run_dirs = [x for x in os.listdir(outdir) if os.path.isdir(os.path.join(outdir, x))]\n    prev_run_ids = [re.match(r'^\\d+', x) for x in prev_run_dirs]\n    prev_run_ids = [int(x.group()) for x in prev_run_ids if x is not None]\n    cur_run_id = max(prev_run_ids, default=-1) + 1\n    c.run_dir = os.path.join(outdir, f'{cur_run_id:05d}-{desc}')\n    assert not os.path.exists(c.run_dir)\n\n    # Print options.\n    print()\n    print('Training options:')\n    print(json.dumps(c, indent=2))\n    print()\n    print(f'Output directory:    {c.run_dir}')\n    print(f'Number of GPUs:      {c.num_gpus}')\n    print(f'Batch size:          {c.batch_size} images')\n    print(f'Training duration:   {c.total_kimg} kimg')\n    print(f'Dataset path:        {c.training_set_kwargs.path}')\n    print(f'Dataset size:        {c.training_set_kwargs.max_size} images')\n    print(f'Dataset resolution:  {c.training_set_kwargs.resolution}')\n    print(f'Dataset labels:      {c.training_set_kwargs.use_labels}')\n    print(f'Dataset x-flips:     {c.training_set_kwargs.xflip}')\n    print()\n\n    # Dry run?\n    if dry_run:\n        print('Dry run; exiting.')\n        return\n\n    # Create output directory.\n    print('Creating output directory...')\n    os.makedirs(c.run_dir)\n    with open(os.path.join(c.run_dir, 'training_options.json'), 'wt') as f:\n        json.dump(c, f, indent=2)\n\n    # Launch processes.\n    print('Launching processes...')\n    torch.multiprocessing.set_start_method('spawn')\n    with tempfile.TemporaryDirectory() as temp_dir:\n        if c.num_gpus == 1:\n            subprocess_fn(rank=0, c=c, temp_dir=temp_dir)\n        else:\n            torch.multiprocessing.spawn(fn=subprocess_fn, args=(c, temp_dir), nprocs=c.num_gpus)\n\n#----------------------------------------------------------------------------\n\ndef init_dataset_kwargs(data):\n    try:\n        dataset_kwargs = dnnlib.EasyDict(class_name='training.dataset.ImageFolderDataset', path=data, use_labels=True, max_size=None, xflip=False)\n        dataset_obj = dnnlib.util.construct_class_by_name(**dataset_kwargs) # Subclass of training.dataset.Dataset.\n        dataset_kwargs.resolution = dataset_obj.resolution # Be explicit about resolution.\n        dataset_kwargs.use_labels = dataset_obj.has_labels # Be explicit about labels.\n        dataset_kwargs.max_size = len(dataset_obj) # Be explicit about dataset size.\n        return dataset_kwargs, dataset_obj.name\n    except IOError as err:\n        raise click.ClickException(f'--data: {err}')\n\n#----------------------------------------------------------------------------\n\ndef parse_comma_separated_list(s):\n    if isinstance(s, list):\n        return s\n    if s is None or s.lower() == 'none' or s == '':\n        return []\n    return s.split(',')\n\n#----------------------------------------------------------------------------\n\n@click.command()\n\n# Required.\n@click.option('--outdir',       help='Where to save the results', metavar='DIR',                required=True)\n@click.option('--cfg',          help='Base configuration',                                      type=click.Choice(['stylegan3-t', 'stylegan3-r', 'stylegan2']), required=True)\n@click.option('--data',         help='Training data', metavar='[ZIP|DIR]',                      type=str, required=True)\n@click.option('--gpus',         help='Number of GPUs to use', metavar='INT',                    type=click.IntRange(min=1), required=True)\n@click.option('--batch',        help='Total batch size', metavar='INT',                         type=click.IntRange(min=1), required=True)\n@click.option('--gamma',        help='R1 regularization weight', metavar='FLOAT',               type=click.FloatRange(min=0), required=True)\n\n# Optional features.\n@click.option('--cond',         help='Train conditional model', metavar='BOOL',                 type=bool, default=False, show_default=True)\n@click.option('--mirror',       help='Enable dataset x-flips', metavar='BOOL',                  type=bool, default=False, show_default=True)\n@click.option('--aug',          help='Augmentation mode',                                       type=click.Choice(['noaug', 'ada', 'fixed']), default='ada', show_default=True)\n@click.option('--resume',       help='Resume from given network pickle', metavar='[PATH|URL]',  type=str)\n@click.option('--freezed',      help='Freeze first layers of D', metavar='INT',                 type=click.IntRange(min=0), default=0, show_default=True)\n\n# Misc hyperparameters.\n@click.option('--p',            help='Probability for --aug=fixed', metavar='FLOAT',            type=click.FloatRange(min=0, max=1), default=0.2, show_default=True)\n@click.option('--target',       help='Target value for --aug=ada', metavar='FLOAT',             type=click.FloatRange(min=0, max=1), default=0.6, show_default=True)\n@click.option('--batch-gpu',    help='Limit batch size per GPU', metavar='INT',                 type=click.IntRange(min=1))\n@click.option('--cbase',        help='Capacity multiplier', metavar='INT',                      type=click.IntRange(min=1), default=32768, show_default=True)\n@click.option('--cmax',         help='Max. feature maps', metavar='INT',                        type=click.IntRange(min=1), default=512, show_default=True)\n@click.option('--glr',          help='G learning rate  [default: varies]', metavar='FLOAT',     type=click.FloatRange(min=0))\n@click.option('--dlr',          help='D learning rate', metavar='FLOAT',                        type=click.FloatRange(min=0), default=0.002, show_default=True)\n@click.option('--map-depth',    help='Mapping network depth  [default: varies]', metavar='INT', type=click.IntRange(min=1))\n@click.option('--mbstd-group',  help='Minibatch std group size', metavar='INT',                 type=click.IntRange(min=1), default=4, show_default=True)\n\n# Misc settings.\n@click.option('--desc',         help='String to include in result dir name', metavar='STR',     type=str)\n@click.option('--metrics',      help='Quality metrics', metavar='[NAME|A,B,C|none]',            type=parse_comma_separated_list, default='fid50k_full', show_default=True)\n@click.option('--kimg',         help='Total training duration', metavar='KIMG',                 type=click.IntRange(min=1), default=25000, show_default=True)\n@click.option('--tick',         help='How often to print progress', metavar='KIMG',             type=click.IntRange(min=1), default=4, show_default=True)\n@click.option('--snap',         help='How often to save snapshots', metavar='TICKS',            type=click.IntRange(min=1), default=50, show_default=True)\n@click.option('--seed',         help='Random seed', metavar='INT',                              type=click.IntRange(min=0), default=0, show_default=True)\n@click.option('--fp32',         help='Disable mixed-precision', metavar='BOOL',                 type=bool, default=False, show_default=True)\n@click.option('--nobench',      help='Disable cuDNN benchmarking', metavar='BOOL',              type=bool, default=False, show_default=True)\n@click.option('--workers',      help='DataLoader worker processes', metavar='INT',              type=click.IntRange(min=1), default=3, show_default=True)\n@click.option('-n','--dry-run', help='Print training options and exit',                         is_flag=True)\n\ndef main(**kwargs):\n    \"\"\"Train a GAN using the techniques described in the paper\n    \"Alias-Free Generative Adversarial Networks\".\n\n    Examples:\n\n    \\b\n    # Train StyleGAN3-T for AFHQv2 using 8 GPUs.\n    python train.py --outdir=~/training-runs --cfg=stylegan3-t --data=~/datasets/afhqv2-512x512.zip \\\\\n        --gpus=8 --batch=32 --gamma=8.2 --mirror=1\n\n    \\b\n    # Fine-tune StyleGAN3-R for MetFaces-U using 1 GPU, starting from the pre-trained FFHQ-U pickle.\n    python train.py --outdir=~/training-runs --cfg=stylegan3-r --data=~/datasets/metfacesu-1024x1024.zip \\\\\n        --gpus=8 --batch=32 --gamma=6.6 --mirror=1 --kimg=5000 --snap=5 \\\\\n        --resume=https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/stylegan3-r-ffhqu-1024x1024.pkl\n\n    \\b\n    # Train StyleGAN2 for FFHQ at 1024x1024 resolution using 8 GPUs.\n    python train.py --outdir=~/training-runs --cfg=stylegan2 --data=~/datasets/ffhq-1024x1024.zip \\\\\n        --gpus=8 --batch=32 --gamma=10 --mirror=1 --aug=noaug\n    \"\"\"\n\n    # Initialize config.\n    opts = dnnlib.EasyDict(kwargs) # Command line arguments.\n    c = dnnlib.EasyDict() # Main config dict.\n    c.G_kwargs = dnnlib.EasyDict(class_name=None, z_dim=512, w_dim=512, mapping_kwargs=dnnlib.EasyDict())\n    c.D_kwargs = dnnlib.EasyDict(class_name='training.networks_stylegan2.Discriminator', block_kwargs=dnnlib.EasyDict(), mapping_kwargs=dnnlib.EasyDict(), epilogue_kwargs=dnnlib.EasyDict())\n    c.G_opt_kwargs = dnnlib.EasyDict(class_name='torch.optim.Adam', betas=[0.0,0.99], eps=1e-8)\n    c.D_opt_kwargs = dnnlib.EasyDict(class_name='torch.optim.Adam', betas=[0.0,0.99], eps=1e-8)\n    c.loss_kwargs = dnnlib.EasyDict(class_name='training.loss.StyleGAN2Loss')\n    c.data_loader_kwargs = dnnlib.EasyDict(pin_memory=True, prefetch_factor=2)\n\n    # Training set.\n    c.training_set_kwargs, dataset_name = init_dataset_kwargs(data=opts.data)\n    if opts.cond and not c.training_set_kwargs.use_labels:\n        raise click.ClickException('--cond=True requires labels specified in dataset.json')\n    c.training_set_kwargs.use_labels = opts.cond\n    c.training_set_kwargs.xflip = opts.mirror\n\n    # Hyperparameters & settings.\n    c.num_gpus = opts.gpus\n    c.batch_size = opts.batch\n    c.batch_gpu = opts.batch_gpu or opts.batch // opts.gpus\n    c.G_kwargs.channel_base = c.D_kwargs.channel_base = opts.cbase\n    c.G_kwargs.channel_max = c.D_kwargs.channel_max = opts.cmax\n    c.G_kwargs.mapping_kwargs.num_layers = (8 if opts.cfg == 'stylegan2' else 2) if opts.map_depth is None else opts.map_depth\n    c.D_kwargs.block_kwargs.freeze_layers = opts.freezed\n    c.D_kwargs.epilogue_kwargs.mbstd_group_size = opts.mbstd_group\n    c.loss_kwargs.r1_gamma = opts.gamma\n    c.G_opt_kwargs.lr = (0.002 if opts.cfg == 'stylegan2' else 0.0025) if opts.glr is None else opts.glr\n    c.D_opt_kwargs.lr = opts.dlr\n    c.metrics = opts.metrics\n    c.total_kimg = opts.kimg\n    c.kimg_per_tick = opts.tick\n    c.image_snapshot_ticks = c.network_snapshot_ticks = opts.snap\n    c.random_seed = c.training_set_kwargs.random_seed = opts.seed\n    c.data_loader_kwargs.num_workers = opts.workers\n\n    # Sanity checks.\n    if c.batch_size % c.num_gpus != 0:\n        raise click.ClickException('--batch must be a multiple of --gpus')\n    if c.batch_size % (c.num_gpus * c.batch_gpu) != 0:\n        raise click.ClickException('--batch must be a multiple of --gpus times --batch-gpu')\n    if c.batch_gpu < c.D_kwargs.epilogue_kwargs.mbstd_group_size:\n        raise click.ClickException('--batch-gpu cannot be smaller than --mbstd')\n    if any(not metric_main.is_valid_metric(metric) for metric in c.metrics):\n        raise click.ClickException('\\n'.join(['--metrics can only contain the following values:'] + metric_main.list_valid_metrics()))\n\n    # Base configuration.\n    c.ema_kimg = c.batch_size * 10 / 32\n    if opts.cfg == 'stylegan2':\n        c.G_kwargs.class_name = 'training.networks_stylegan2.Generator'\n        c.loss_kwargs.style_mixing_prob = 0.9 # Enable style mixing regularization.\n        c.loss_kwargs.pl_weight = 2 # Enable path length regularization.\n        c.G_reg_interval = 4 # Enable lazy regularization for G.\n        c.G_kwargs.fused_modconv_default = 'inference_only' # Speed up training by using regular convolutions instead of grouped convolutions.\n        c.loss_kwargs.pl_no_weight_grad = True # Speed up path length regularization by skipping gradient computation wrt. conv2d weights.\n    else:\n        c.G_kwargs.class_name = 'training.networks_stylegan3.Generator'\n        c.G_kwargs.magnitude_ema_beta = 0.5 ** (c.batch_size / (20 * 1e3))\n        if opts.cfg == 'stylegan3-r':\n            c.G_kwargs.conv_kernel = 1 # Use 1x1 convolutions.\n            c.G_kwargs.channel_base *= 2 # Double the number of feature maps.\n            c.G_kwargs.channel_max *= 2\n            c.G_kwargs.use_radial_filters = True # Use radially symmetric downsampling filters.\n            c.loss_kwargs.blur_init_sigma = 10 # Blur the images seen by the discriminator.\n            c.loss_kwargs.blur_fade_kimg = c.batch_size * 200 / 32 # Fade out the blur during the first N kimg.\n\n    # Augmentation.\n    if opts.aug != 'noaug':\n        c.augment_kwargs = dnnlib.EasyDict(class_name='training.augment.AugmentPipe', xflip=1, rotate90=1, xint=1, scale=1, rotate=1, aniso=1, xfrac=1, brightness=1, contrast=1, lumaflip=1, hue=1, saturation=1)\n        if opts.aug == 'ada':\n            c.ada_target = opts.target\n        if opts.aug == 'fixed':\n            c.augment_p = opts.p\n\n    # Resume.\n    if opts.resume is not None:\n        c.resume_pkl = opts.resume\n        c.ada_kimg = 100 # Make ADA react faster at the beginning.\n        c.ema_rampup = None # Disable EMA rampup.\n        c.loss_kwargs.blur_init_sigma = 0 # Disable blur rampup.\n\n    # Performance-related toggles.\n    if opts.fp32:\n        c.G_kwargs.num_fp16_res = c.D_kwargs.num_fp16_res = 0\n        c.G_kwargs.conv_clamp = c.D_kwargs.conv_clamp = None\n    if opts.nobench:\n        c.cudnn_benchmark = False\n\n    # Description string.\n    desc = f'{opts.cfg:s}-{dataset_name:s}-gpus{c.num_gpus:d}-batch{c.batch_size:d}-gamma{c.loss_kwargs.r1_gamma:g}'\n    if opts.desc is not None:\n        desc += f'-{opts.desc}'\n\n    # Launch.\n    launch_training(c=c, desc=desc, outdir=opts.outdir, dry_run=opts.dry_run)\n\n#----------------------------------------------------------------------------\n\nif __name__ == \"__main__\":\n    main() # pylint: disable=no-value-for-parameter\n\n#----------------------------------------------------------------------------\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T12:52:02.592033Z","iopub.execute_input":"2025-06-09T12:52:02.592580Z","iopub.status.idle":"2025-06-09T12:52:02.604649Z","shell.execute_reply.started":"2025-06-09T12:52:02.592559Z","shell.execute_reply":"2025-06-09T12:52:02.603925Z"},"jupyter":{"source_hidden":true}},"outputs":[{"name":"stdout","text":"Overwriting /kaggle/working/stylegan3/train.py\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"%load /kaggle/working/stylegan3/train.py\n\ntorch.optim.Adam [0.0,0.99]","metadata":{}}]}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba6642a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ninja scipy click tqdm pyspng imageio-ffmpeg\n",
    "!pip install torch torchvision --extra-index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07ded1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'stylegan3'...\n",
      "remote: Enumerating objects: 212, done.\u001b[K\n",
      "remote: Counting objects: 100% (163/163), done.\u001b[K\n",
      "remote: Compressing objects: 100% (73/73), done.\u001b[K\n",
      "remote: Total 212 (delta 99), reused 90 (delta 90), pack-reused 49 (from 1)\u001b[K\n",
      "Receiving objects: 100% (212/212), 4.16 MiB | 379.00 KiB/s, done.\n",
      "Resolving deltas: 100% (108/108), done.\n",
      "/home/ansh-yadav/Music/Subjects/Project/website/stylegan3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ansh-yadav/.miniconda3/envs/jupyter-lab/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/NVlabs/stylegan3.git\n",
    "%cd stylegan3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862d5a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"iamsouravbanerjee/animal-image-dataset-90-different-animals\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcae6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile /kaggle/working/stylegan3/train.py\n",
    "# %load /kaggle/working/stylegan3/train.py\n",
    "# Copyright (c) 2021, NVIDIA CORPORATION & AFFILIATES.  All rights reserved.\n",
    "#\n",
    "# NVIDIA CORPORATION and its licensors retain all intellectual property\n",
    "# and proprietary rights in and to this software, related documentation\n",
    "# and any modifications thereto.  Any use, reproduction, disclosure or\n",
    "# distribution of this software and related documentation without an express\n",
    "# license agreement from NVIDIA CORPORATION is strictly prohibited.\n",
    "\n",
    "\"\"\"Train a GAN using the techniques described in the paper\n",
    "\"Alias-Free Generative Adversarial Networks\".\"\"\"\n",
    "\n",
    "import os\n",
    "import click\n",
    "import re\n",
    "import json\n",
    "import tempfile\n",
    "import torch\n",
    "\n",
    "import dnnlib\n",
    "from training import training_loop\n",
    "from metrics import metric_main\n",
    "from torch_utils import training_stats\n",
    "from torch_utils import custom_ops\n",
    "\n",
    "#----------------------------------------------------------------------------\n",
    "\n",
    "def subprocess_fn(rank, c, temp_dir):\n",
    "    dnnlib.util.Logger(file_name=os.path.join(c.run_dir, 'log.txt'), file_mode='a', should_flush=True)\n",
    "\n",
    "    # Init torch.distributed.\n",
    "    if c.num_gpus > 1:\n",
    "        init_file = os.path.abspath(os.path.join(temp_dir, '.torch_distributed_init'))\n",
    "        if os.name == 'nt':\n",
    "            init_method = 'file:///' + init_file.replace('\\\\', '/')\n",
    "            torch.distributed.init_process_group(backend='gloo', init_method=init_method, rank=rank, world_size=c.num_gpus)\n",
    "        else:\n",
    "            init_method = f'file://{init_file}'\n",
    "            torch.distributed.init_process_group(backend='nccl', init_method=init_method, rank=rank, world_size=c.num_gpus)\n",
    "\n",
    "    # Init torch_utils.\n",
    "    sync_device = torch.device('cuda', rank) if c.num_gpus > 1 else None\n",
    "    training_stats.init_multiprocessing(rank=rank, sync_device=sync_device)\n",
    "    if rank != 0:\n",
    "        custom_ops.verbosity = 'none'\n",
    "\n",
    "    # Execute training loop.\n",
    "    training_loop.training_loop(rank=rank, **c)\n",
    "\n",
    "#----------------------------------------------------------------------------\n",
    "\n",
    "def launch_training(c, desc, outdir, dry_run):\n",
    "    dnnlib.util.Logger(should_flush=True)\n",
    "\n",
    "    # Pick output directory.\n",
    "    prev_run_dirs = []\n",
    "    if os.path.isdir(outdir):\n",
    "        prev_run_dirs = [x for x in os.listdir(outdir) if os.path.isdir(os.path.join(outdir, x))]\n",
    "    prev_run_ids = [re.match(r'^\\d+', x) for x in prev_run_dirs]\n",
    "    prev_run_ids = [int(x.group()) for x in prev_run_ids if x is not None]\n",
    "    cur_run_id = max(prev_run_ids, default=-1) + 1\n",
    "    c.run_dir = os.path.join(outdir, f'{cur_run_id:05d}-{desc}')\n",
    "    assert not os.path.exists(c.run_dir)\n",
    "\n",
    "    # Print options.\n",
    "    print()\n",
    "    print('Training options:')\n",
    "    print(json.dumps(c, indent=2))\n",
    "    print()\n",
    "    print(f'Output directory:    {c.run_dir}')\n",
    "    print(f'Number of GPUs:      {c.num_gpus}')\n",
    "    print(f'Batch size:          {c.batch_size} images')\n",
    "    print(f'Training duration:   {c.total_kimg} kimg')\n",
    "    print(f'Dataset path:        {c.training_set_kwargs.path}')\n",
    "    print(f'Dataset size:        {c.training_set_kwargs.max_size} images')\n",
    "    print(f'Dataset resolution:  {c.training_set_kwargs.resolution}')\n",
    "    print(f'Dataset labels:      {c.training_set_kwargs.use_labels}')\n",
    "    print(f'Dataset x-flips:     {c.training_set_kwargs.xflip}')\n",
    "    print()\n",
    "\n",
    "    # Dry run?\n",
    "    if dry_run:\n",
    "        print('Dry run; exiting.')\n",
    "        return\n",
    "\n",
    "    # Create output directory.\n",
    "    print('Creating output directory...')\n",
    "    os.makedirs(c.run_dir)\n",
    "    with open(os.path.join(c.run_dir, 'training_options.json'), 'wt') as f:\n",
    "        json.dump(c, f, indent=2)\n",
    "\n",
    "    # Launch processes.\n",
    "    print('Launching processes...')\n",
    "    torch.multiprocessing.set_start_method('spawn')\n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        if c.num_gpus == 1:\n",
    "            subprocess_fn(rank=0, c=c, temp_dir=temp_dir)\n",
    "        else:\n",
    "            torch.multiprocessing.spawn(fn=subprocess_fn, args=(c, temp_dir), nprocs=c.num_gpus)\n",
    "\n",
    "#----------------------------------------------------------------------------\n",
    "\n",
    "def init_dataset_kwargs(data):\n",
    "    try:\n",
    "        dataset_kwargs = dnnlib.EasyDict(class_name='training.dataset.ImageFolderDataset', path=data, use_labels=True, max_size=None, xflip=False)\n",
    "        dataset_obj = dnnlib.util.construct_class_by_name(**dataset_kwargs) # Subclass of training.dataset.Dataset.\n",
    "        dataset_kwargs.resolution = dataset_obj.resolution # Be explicit about resolution.\n",
    "        dataset_kwargs.use_labels = dataset_obj.has_labels # Be explicit about labels.\n",
    "        dataset_kwargs.max_size = len(dataset_obj) # Be explicit about dataset size.\n",
    "        return dataset_kwargs, dataset_obj.name\n",
    "    except IOError as err:\n",
    "        raise click.ClickException(f'--data: {err}')\n",
    "\n",
    "#----------------------------------------------------------------------------\n",
    "\n",
    "def parse_comma_separated_list(s):\n",
    "    if isinstance(s, list):\n",
    "        return s\n",
    "    if s is None or s.lower() == 'none' or s == '':\n",
    "        return []\n",
    "    return s.split(',')\n",
    "\n",
    "#----------------------------------------------------------------------------\n",
    "\n",
    "@click.command()\n",
    "\n",
    "# Required.\n",
    "@click.option('--outdir',       help='Where to save the results', metavar='DIR',                required=True)\n",
    "@click.option('--cfg',          help='Base configuration',                                      type=click.Choice(['stylegan3-t', 'stylegan3-r', 'stylegan2']), required=True)\n",
    "@click.option('--data',         help='Training data', metavar='[ZIP|DIR]',                      type=str, required=True)\n",
    "@click.option('--gpus',         help='Number of GPUs to use', metavar='INT',                    type=click.IntRange(min=1), required=True)\n",
    "@click.option('--batch',        help='Total batch size', metavar='INT',                         type=click.IntRange(min=1), required=True)\n",
    "@click.option('--gamma',        help='R1 regularization weight', metavar='FLOAT',               type=click.FloatRange(min=0), required=True)\n",
    "\n",
    "# Optional features.\n",
    "@click.option('--cond',         help='Train conditional model', metavar='BOOL',                 type=bool, default=False, show_default=True)\n",
    "@click.option('--mirror',       help='Enable dataset x-flips', metavar='BOOL',                  type=bool, default=False, show_default=True)\n",
    "@click.option('--aug',          help='Augmentation mode',                                       type=click.Choice(['noaug', 'ada', 'fixed']), default='ada', show_default=True)\n",
    "@click.option('--resume',       help='Resume from given network pickle', metavar='[PATH|URL]',  type=str)\n",
    "@click.option('--freezed',      help='Freeze first layers of D', metavar='INT',                 type=click.IntRange(min=0), default=0, show_default=True)\n",
    "\n",
    "# Misc hyperparameters.\n",
    "@click.option('--p',            help='Probability for --aug=fixed', metavar='FLOAT',            type=click.FloatRange(min=0, max=1), default=0.2, show_default=True)\n",
    "@click.option('--target',       help='Target value for --aug=ada', metavar='FLOAT',             type=click.FloatRange(min=0, max=1), default=0.6, show_default=True)\n",
    "@click.option('--batch-gpu',    help='Limit batch size per GPU', metavar='INT',                 type=click.IntRange(min=1))\n",
    "@click.option('--cbase',        help='Capacity multiplier', metavar='INT',                      type=click.IntRange(min=1), default=32768, show_default=True)\n",
    "@click.option('--cmax',         help='Max. feature maps', metavar='INT',                        type=click.IntRange(min=1), default=512, show_default=True)\n",
    "@click.option('--glr',          help='G learning rate  [default: varies]', metavar='FLOAT',     type=click.FloatRange(min=0))\n",
    "@click.option('--dlr',          help='D learning rate', metavar='FLOAT',                        type=click.FloatRange(min=0), default=0.002, show_default=True)\n",
    "@click.option('--map-depth',    help='Mapping network depth  [default: varies]', metavar='INT', type=click.IntRange(min=1))\n",
    "@click.option('--mbstd-group',  help='Minibatch std group size', metavar='INT',                 type=click.IntRange(min=1), default=4, show_default=True)\n",
    "\n",
    "# Misc settings.\n",
    "@click.option('--desc',         help='String to include in result dir name', metavar='STR',     type=str)\n",
    "@click.option('--metrics',      help='Quality metrics', metavar='[NAME|A,B,C|none]',            type=parse_comma_separated_list, default='fid50k_full', show_default=True)\n",
    "@click.option('--kimg',         help='Total training duration', metavar='KIMG',                 type=click.IntRange(min=1), default=25000, show_default=True)\n",
    "@click.option('--tick',         help='How often to print progress', metavar='KIMG',             type=click.IntRange(min=1), default=4, show_default=True)\n",
    "@click.option('--snap',         help='How often to save snapshots', metavar='TICKS',            type=click.IntRange(min=1), default=50, show_default=True)\n",
    "@click.option('--seed',         help='Random seed', metavar='INT',                              type=click.IntRange(min=0), default=0, show_default=True)\n",
    "@click.option('--fp32',         help='Disable mixed-precision', metavar='BOOL',                 type=bool, default=False, show_default=True)\n",
    "@click.option('--nobench',      help='Disable cuDNN benchmarking', metavar='BOOL',              type=bool, default=False, show_default=True)\n",
    "@click.option('--workers',      help='DataLoader worker processes', metavar='INT',              type=click.IntRange(min=1), default=3, show_default=True)\n",
    "@click.option('-n','--dry-run', help='Print training options and exit',                         is_flag=True)\n",
    "\n",
    "def main(**kwargs):\n",
    "    \"\"\"Train a GAN using the techniques described in the paper\n",
    "    \"Alias-Free Generative Adversarial Networks\".\n",
    "\n",
    "    Examples:\n",
    "\n",
    "    \\b\n",
    "    # Train StyleGAN3-T for AFHQv2 using 8 GPUs.\n",
    "    python train.py --outdir=~/training-runs --cfg=stylegan3-t --data=~/datasets/afhqv2-512x512.zip \\\\\n",
    "        --gpus=8 --batch=32 --gamma=8.2 --mirror=1\n",
    "\n",
    "    \\b\n",
    "    # Fine-tune StyleGAN3-R for MetFaces-U using 1 GPU, starting from the pre-trained FFHQ-U pickle.\n",
    "    python train.py --outdir=~/training-runs --cfg=stylegan3-r --data=~/datasets/metfacesu-1024x1024.zip \\\\\n",
    "        --gpus=8 --batch=32 --gamma=6.6 --mirror=1 --kimg=5000 --snap=5 \\\\\n",
    "        --resume=https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/stylegan3-r-ffhqu-1024x1024.pkl\n",
    "\n",
    "    \\b\n",
    "    # Train StyleGAN2 for FFHQ at 1024x1024 resolution using 8 GPUs.\n",
    "    python train.py --outdir=~/training-runs --cfg=stylegan2 --data=~/datasets/ffhq-1024x1024.zip \\\\\n",
    "        --gpus=8 --batch=32 --gamma=10 --mirror=1 --aug=noaug\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize config.\n",
    "    opts = dnnlib.EasyDict(kwargs) # Command line arguments.\n",
    "    c = dnnlib.EasyDict() # Main config dict.\n",
    "    c.G_kwargs = dnnlib.EasyDict(class_name=None, z_dim=512, w_dim=512, mapping_kwargs=dnnlib.EasyDict())\n",
    "    c.D_kwargs = dnnlib.EasyDict(class_name='training.networks_stylegan2.Discriminator', block_kwargs=dnnlib.EasyDict(), mapping_kwargs=dnnlib.EasyDict(), epilogue_kwargs=dnnlib.EasyDict())\n",
    "    c.G_opt_kwargs = dnnlib.EasyDict(class_name='torch.optim.Adam', betas=[0.0,0.99], eps=1e-8)\n",
    "    c.D_opt_kwargs = dnnlib.EasyDict(class_name='torch.optim.Adam', betas=[0.0,0.99], eps=1e-8)\n",
    "    c.loss_kwargs = dnnlib.EasyDict(class_name='training.loss.StyleGAN2Loss')\n",
    "    c.data_loader_kwargs = dnnlib.EasyDict(pin_memory=True, prefetch_factor=2)\n",
    "\n",
    "    # Training set.\n",
    "    c.training_set_kwargs, dataset_name = init_dataset_kwargs(data=opts.data)\n",
    "    if opts.cond and not c.training_set_kwargs.use_labels:\n",
    "        raise click.ClickException('--cond=True requires labels specified in dataset.json')\n",
    "    c.training_set_kwargs.use_labels = opts.cond\n",
    "    c.training_set_kwargs.xflip = opts.mirror\n",
    "\n",
    "    # Hyperparameters & settings.\n",
    "    c.num_gpus = opts.gpus\n",
    "    c.batch_size = opts.batch\n",
    "    c.batch_gpu = opts.batch_gpu or opts.batch // opts.gpus\n",
    "    c.G_kwargs.channel_base = c.D_kwargs.channel_base = opts.cbase\n",
    "    c.G_kwargs.channel_max = c.D_kwargs.channel_max = opts.cmax\n",
    "    c.G_kwargs.mapping_kwargs.num_layers = (8 if opts.cfg == 'stylegan2' else 2) if opts.map_depth is None else opts.map_depth\n",
    "    c.D_kwargs.block_kwargs.freeze_layers = opts.freezed\n",
    "    c.D_kwargs.epilogue_kwargs.mbstd_group_size = opts.mbstd_group\n",
    "    c.loss_kwargs.r1_gamma = opts.gamma\n",
    "    c.G_opt_kwargs.lr = (0.002 if opts.cfg == 'stylegan2' else 0.0025) if opts.glr is None else opts.glr\n",
    "    c.D_opt_kwargs.lr = opts.dlr\n",
    "    c.metrics = opts.metrics\n",
    "    c.total_kimg = opts.kimg\n",
    "    c.kimg_per_tick = opts.tick\n",
    "    c.image_snapshot_ticks = c.network_snapshot_ticks = opts.snap\n",
    "    c.random_seed = c.training_set_kwargs.random_seed = opts.seed\n",
    "    c.data_loader_kwargs.num_workers = opts.workers\n",
    "\n",
    "    # Sanity checks.\n",
    "    if c.batch_size % c.num_gpus != 0:\n",
    "        raise click.ClickException('--batch must be a multiple of --gpus')\n",
    "    if c.batch_size % (c.num_gpus * c.batch_gpu) != 0:\n",
    "        raise click.ClickException('--batch must be a multiple of --gpus times --batch-gpu')\n",
    "    if c.batch_gpu < c.D_kwargs.epilogue_kwargs.mbstd_group_size:\n",
    "        raise click.ClickException('--batch-gpu cannot be smaller than --mbstd')\n",
    "    if any(not metric_main.is_valid_metric(metric) for metric in c.metrics):\n",
    "        raise click.ClickException('\\n'.join(['--metrics can only contain the following values:'] + metric_main.list_valid_metrics()))\n",
    "\n",
    "    # Base configuration.\n",
    "    c.ema_kimg = c.batch_size * 10 / 32\n",
    "    if opts.cfg == 'stylegan2':\n",
    "        c.G_kwargs.class_name = 'training.networks_stylegan2.Generator'\n",
    "        c.loss_kwargs.style_mixing_prob = 0.9 # Enable style mixing regularization.\n",
    "        c.loss_kwargs.pl_weight = 2 # Enable path length regularization.\n",
    "        c.G_reg_interval = 4 # Enable lazy regularization for G.\n",
    "        c.G_kwargs.fused_modconv_default = 'inference_only' # Speed up training by using regular convolutions instead of grouped convolutions.\n",
    "        c.loss_kwargs.pl_no_weight_grad = True # Speed up path length regularization by skipping gradient computation wrt. conv2d weights.\n",
    "    else:\n",
    "        c.G_kwargs.class_name = 'training.networks_stylegan3.Generator'\n",
    "        c.G_kwargs.magnitude_ema_beta = 0.5 ** (c.batch_size / (20 * 1e3))\n",
    "        if opts.cfg == 'stylegan3-r':\n",
    "            c.G_kwargs.conv_kernel = 1 # Use 1x1 convolutions.\n",
    "            c.G_kwargs.channel_base *= 2 # Double the number of feature maps.\n",
    "            c.G_kwargs.channel_max *= 2\n",
    "            c.G_kwargs.use_radial_filters = True # Use radially symmetric downsampling filters.\n",
    "            c.loss_kwargs.blur_init_sigma = 10 # Blur the images seen by the discriminator.\n",
    "            c.loss_kwargs.blur_fade_kimg = c.batch_size * 200 / 32 # Fade out the blur during the first N kimg.\n",
    "\n",
    "    # Augmentation.\n",
    "    if opts.aug != 'noaug':\n",
    "        c.augment_kwargs = dnnlib.EasyDict(class_name='training.augment.AugmentPipe', xflip=1, rotate90=1, xint=1, scale=1, rotate=1, aniso=1, xfrac=1, brightness=1, contrast=1, lumaflip=1, hue=1, saturation=1)\n",
    "        if opts.aug == 'ada':\n",
    "            c.ada_target = opts.target\n",
    "        if opts.aug == 'fixed':\n",
    "            c.augment_p = opts.p\n",
    "\n",
    "    # Resume.\n",
    "    if opts.resume is not None:\n",
    "        c.resume_pkl = opts.resume\n",
    "        c.ada_kimg = 100 # Make ADA react faster at the beginning.\n",
    "        c.ema_rampup = None # Disable EMA rampup.\n",
    "        c.loss_kwargs.blur_init_sigma = 0 # Disable blur rampup.\n",
    "\n",
    "    # Performance-related toggles.\n",
    "    if opts.fp32:\n",
    "        c.G_kwargs.num_fp16_res = c.D_kwargs.num_fp16_res = 0\n",
    "        c.G_kwargs.conv_clamp = c.D_kwargs.conv_clamp = None\n",
    "    if opts.nobench:\n",
    "        c.cudnn_benchmark = False\n",
    "\n",
    "    # Description string.\n",
    "    desc = f'{opts.cfg:s}-{dataset_name:s}-gpus{c.num_gpus:d}-batch{c.batch_size:d}-gamma{c.loss_kwargs.r1_gamma:g}'\n",
    "    if opts.desc is not None:\n",
    "        desc += f'-{opts.desc}'\n",
    "\n",
    "    # Launch.\n",
    "    launch_training(c=c, desc=desc, outdir=opts.outdir, dry_run=opts.dry_run)\n",
    "\n",
    "#----------------------------------------------------------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main() # pylint: disable=no-value-for-parameter\n",
    "\n",
    "#----------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5b02af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For StyleGAN2-ADA / StyleGAN3 (latest version):\n",
    "!python /kaggle/working/stylegan3/dataset_tool.py --source=/kaggle/working/animal_dataset --dest=/kaggle/working/animal_dataset-512x512.zip --resolution=512x512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee69010",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7997cc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/stylegan3-r-afhqv2-512x512.pkl -O stylegan3-pretrained-512x512.pkl\n",
    "!mv stylegan3-pretrained-512x512.pkl /kaggle/working/\n",
    "!ls -lh /kaggle/working/stylegan3-pretrained-512x512.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258050dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace this logic in your launch_training or run script\n",
    "from training import training_loop\n",
    "import legacy\n",
    "\n",
    "with open('/kaggle/working/stylegan3-pretrained-512x512.pkl', 'rb') as f:\n",
    "    resume_data = legacy.load_network_pkl(f)\n",
    "    G = resume_data['G']\n",
    "    print(G.z_dim, G.w_dim, G.mapping.num_layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50154d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128,expandable_segments:True\n",
    "!export TORCH_CUDA_ARCH_LIST=\"7.5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b0dab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python /kaggle/working/stylegan3/train.py \\\n",
    "  --outdir=/kaggle/working/animal-stylegan-results-512x512 \\\n",
    "  --cfg=stylegan3-r \\\n",
    "  --data=/kaggle/working/animal_dataset-512x512.zip \\\n",
    "  --gpus=1 \\\n",
    "  --batch=8 \\\n",
    "  --mirror=1 \\\n",
    "  --gamma=8 \\\n",
    "  --snap=1 \\\n",
    "  --resume=/kaggle/working/stylegan3-pretrained-512x512.pkl \\\n",
    "  --kimg=5000 \\\n",
    "  --metrics=none \\\n",
    "  --glr=0.002 \\\n",
    "  --dlr=0.002 \\\n",
    "  --aug=ada \\\n",
    "  --freezed=0 \\\n",
    "  --workers=4 \\\n",
    "  --target=0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16e16a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python /kaggle/working/stylegan3/gen_images.py \\\n",
    "  --outdir=/kaggle/working/generated-animals-512x512 \\\n",
    "  --trunc=1 \\\n",
    "  --seeds=1-20 \\\n",
    "  --network=/kaggle/working/animal-stylegan-results-512x512/00006-stylegan3-r-animal_dataset-512x512-gpus1-batch8-gamma8/network-snapshot-000000.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd18e23b",
   "metadata": {},
   "outputs": [],
   "source": [
    " python ./stylegan3/gen_images.py   --outdir=./generated-animals-512x512   --trunc=1   --seeds=1-20   --network=./network-snapshot-000000.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c716e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce GTX 1650\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  # should return True\n",
    "print(torch.cuda.get_device_name(0))  # should return your GPU name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84466f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "export CUDA_HOME=/usr/local/cuda\n",
    "export PATH=$CUDA_HOME/bin:$PATH\n",
    "export LD_LIBRARY_PATH=$CUDA_HOME/lib64:$LD_LIBRARY_PATH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c88f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "echo 'export CUDA_HOME=/usr/local/cuda' >> ~/.bashrc\n",
    "echo 'export PATH=$CUDA_HOME/bin:$PATH' >> ~/.bashrc\n",
    "echo 'export LD_LIBRARY_PATH=$CUDA_HOME/lib64:$LD_LIBRARY_PATH' >> ~/.bashrc\n",
    "source ~/.bashrc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8616f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "nvcc --version\n",
    "nvidia-smi\n",
    "echo $CUDA_HOME\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800e3696",
   "metadata": {},
   "outputs": [],
   "source": [
    "python -c \"import torch; print(torch.cuda.is_available())\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2e41cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "image_path = [\"fakes000000.png\",\"fakes_init.png\",\"reals.png\"]\n",
    "for i in range(len(image_path)):    \n",
    "    img = mpimg.imread(f'/kaggle/working/animal-stylegan-results-512x512/00000-stylegan3-r-animal_dataset-512x512-gpus1-batch8-gamma8/{image_path[i]}')\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title(image_path[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95477f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Define the folder path containing the images\n",
    "folder_path = \"/kaggle/working/generated-animals-512x512\"\n",
    "\n",
    "# Get all PNG images in the folder\n",
    "image_paths = sorted(glob.glob(os.path.join(folder_path, \"*.png\")))\n",
    "\n",
    "# Define the number of images per row in the grid\n",
    "images_per_row = 4\n",
    "total_images = len(image_paths)\n",
    "rows = (total_images + images_per_row - 1) // images_per_row  # Ceiling division\n",
    "\n",
    "# Create a figure\n",
    "plt.figure(figsize=(images_per_row * 4, rows * 4))\n",
    "\n",
    "# Loop through each image and plot it\n",
    "for idx, image_path in enumerate(image_paths):\n",
    "    img = mpimg.imread(image_path)\n",
    "    plt.subplot(rows, images_per_row, idx + 1)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Image {idx + 1}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4936a54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previous training run: look up options automatically, save result to JSONL file.\n",
    "!python /kaggle/working/stylegan3/calc_metrics.py --metrics=eqr50k,eqt50k_int \\\n",
    "    --network=/kaggle/working/animal-stylegan-results-512x512/00000-stylegan3-r-animal_dataset-512x512-gpus1-batch8-gamma8/network-snapshot-000000.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e74ec6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate dataset mean and std, needed in subsequent steps.\n",
    "!python avg_spectra.py stats --source=/kaggle/working/animal_dataset-512x512.zip\n",
    "\n",
    "# Calculate average spectrum for the training data.\n",
    "!python avg_spectra.py calc --source=/kaggle/working/animal_dataset-512x512.zip \\\n",
    "    --dest=/kaggle/working/training-data.npz --mean=112.684 --std=69.509\n",
    "\n",
    "# Calculate average spectrum for a pre-trained generator.\n",
    "!python avg_spectra.py calc \\\n",
    "    --source=/kaggle/working/stylegan3-pretrained-512x512.pkl \\\n",
    "    --dest=/kaggle/working/stylegan3-r.npz --mean=112.684 --std=69.509 --num=70000\n",
    "\n",
    "# Display results.\n",
    "!python avg_spectra.py heatmap /kaggle/working/training-data.npz\n",
    "!python avg_spectra.py heatmap /kaggle/working/stylegan3-r.npz\n",
    "!python avg_spectra.py slices /kaggle/working/training-data.npz /kaggle/working/stylegan3-r.npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64828a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %rm -rf /kaggle/working/animal-stylegan-results-512x512"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter-lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
